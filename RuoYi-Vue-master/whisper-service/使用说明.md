# Whisper 视频转录服务 - 使用说明

## 📖 这是什么？

**Whisper服务** 是一个**视频语音识别服务**，用于将视频中的语音转换成文字。

### 作用流程

```
视频文件 (xxx.mp4)
    ↓
[提取音频] ← ffmpeg工具
    ↓
音频文件 (xxx.wav)
    ↓
[语音识别] ← Whisper AI模型
    ↓
文字内容 ("今天我们学习Java面向对象编程...")
    ↓
[知识点抽取] ← 千问AI
    ↓
知识点列表 (面向对象编程、类、对象、封装...)
```

### 效果对比

| 方式 | 抽取知识点数量 | 知识点来源 |
|------|--------------|-----------|
| **不用Whisper** | 1-2个 | 从视频标题猜测 |
| **使用Whisper** | 15-20个 | 从实际讲解内容提取 |

---

## 🚀 快速启动（3步）

### 步骤1：安装依赖（首次使用，约2分钟）

```bash
# 进入whisper-service目录
cd C:\smartclassv2\RuoYi-Vue-master\whisper-service

# 安装Python依赖包
pip install openai-whisper flask flask-cors
```

**这一步做什么？**
- 安装 `openai-whisper`：语音识别核心库
- 安装 `flask`：Web服务框架，提供HTTP接口
- 安装 `flask-cors`：允许跨域访问

**预期输出**：
```
Collecting openai-whisper
  Downloading openai_whisper-...
...
Successfully installed openai-whisper flask flask-cors torch numpy...
```

---

### 步骤2：启动服务（每次使用）

```bash
python whisper_server.py
```

**这一步做什么？**
- 启动Flask Web服务器
- 加载Whisper tiny模型（首次会自动下载39MB）
- 监听5000端口，等待Java后端调用

**首次运行**（需要下载模型）：
```
Downloading tiny model...
100%|████████████████████| 39.0M/39.0M [00:10<00:00]
Loading model: tiny
Model loaded successfully
 * Running on http://0.0.0.0:5000
```

**后续运行**（直接启动）：
```
Loading model: tiny
Model loaded successfully
 * Running on http://0.0.0.0:5000
```

✅ **看到 "Running on http://0.0.0.0:5000" 表示成功！**

⚠️ **重要**：保持这个窗口打开，不要关闭！

---

### 步骤3：验证服务（可选）

打开浏览器访问：
```
http://localhost:5000/health
```

**应该看到**：
```json
{
  "status": "ok",
  "service": "whisper-transcription",
  "loaded_models": ["tiny"]
}
```

**这一步做什么？**
- 检查服务是否正常运行
- 确认模型是否加载成功

---

## 📁 文件说明

### 核心文件

| 文件 | 作用 | 说明 |
|------|------|------|
| `whisper_server.py` | 核心服务程序 | Flask Web服务，提供语音识别API |
| `requirements.txt` | 依赖列表 | 记录需要安装的Python包 |

### 启动脚本

| 文件 | 作用 | 使用场景 |
|------|------|---------|
| `install_and_start.bat` | 一键安装+启动 | Windows用户，首次使用 |
| `start.bat` | 快速启动 | Windows用户，已安装依赖 |
| `start.sh` | 快速启动 | Linux/Mac用户 |

### 测试工具

| 文件 | 作用 | 使用方法 |
|------|------|---------|
| `test_whisper.py` | 测试转录功能 | `python test_whisper.py <视频文件>` |
| `test_confidence.py` | 查看置信度说明 | `python test_confidence.py` |

---

## 🔧 详细说明

### 1. 安装依赖（pip install）

**命令**：
```bash
pip install openai-whisper flask flask-cors
```

**每个包的作用**：

#### openai-whisper
- **作用**：OpenAI开源的语音识别模型
- **功能**：将音频转换成文字
- **模型**：我们使用tiny模型（最快，准确率85%）
- **大小**：首次运行会下载39MB模型文件

#### flask
- **作用**：Python Web框架
- **功能**：创建HTTP服务器，接收Java后端的请求
- **端口**：监听5000端口

#### flask-cors
- **作用**：跨域资源共享
- **功能**：允许Java后端（不同端口）调用此服务

**安装位置**：
- 如果看到 "Defaulting to user installation"，会安装到用户目录
- 这是正常的，不影响使用

---

### 2. 启动服务（python whisper_server.py）

**启动后发生了什么？**

#### 第1步：加载Whisper模型
```python
# whisper_server.py 会执行：
model = whisper.load_model("tiny")
```
- 首次运行：从网络下载tiny模型（39MB）
- 后续运行：从缓存加载模型（几秒钟）

#### 第2步：启动Flask服务
```python
app.run(host='0.0.0.0', port=5000)
```
- 监听所有网络接口（0.0.0.0）
- 端口：5000
- 等待HTTP请求

#### 第3步：提供API接口

**健康检查接口**：
```
GET http://localhost:5000/health
返回：{"status": "ok", "loaded_models": ["tiny"]}
```

**转录接口**：
```
POST http://localhost:5000/transcribe
参数：视频文件（multipart/form-data）
返回：{"text": "识别出的文字内容"}
```

---

### 3. Java后端如何调用

**Java代码**（已实现）：
```java
// VideoTranscriptionService.java
public String extractTextFromVideo(Video video) {
    // 1. 下载视频文件
    File videoFile = downloadVideo(video.getUrl());
    
    // 2. 调用Whisper服务
    String whisperUrl = "http://localhost:5000/transcribe";
    MultipartFile file = new FileSystemResource(videoFile);
    ResponseEntity<Map> response = restTemplate.postForEntity(whisperUrl, file, Map.class);
    
    // 3. 获取识别结果
    String text = response.getBody().get("text");
    return text;
}
```

**调用流程**：
```
Java后端
  ↓ HTTP POST (视频文件)
Whisper服务 (localhost:5000)
  ↓ 提取音频 (ffmpeg)
  ↓ 语音识别 (Whisper AI)
  ↓ HTTP Response (文字内容)
Java后端
  ↓ 调用千问AI
  ↓ 抽取知识点
知识图谱
```

---

## 💡 常见问题

### Q1：为什么要一直开着窗口？

**答**：Whisper服务是一个**常驻服务**，类似于数据库或Web服务器。

- Java后端需要时会调用它
- 关闭窗口 = 停止服务
- Java后端调用会失败

### Q2：每次都要手动启动吗？

**答**：是的，目前需要手动启动。

**未来优化**：
- 可以配置为Windows服务（开机自启）
- 或使用进程管理工具（如PM2）

### Q3：占用多少资源？

**答**：
- 内存：约1GB（tiny模型）
- CPU：空闲时几乎不占用，转录时会占用
- 磁盘：约200MB（模型+依赖）

### Q4：可以同时处理多个视频吗？

**答**：可以，但会排队处理。

- Flask默认单线程
- 多个请求会依次处理
- 如需并发，可以配置多进程

---

## 🎯 使用场景

### 场景1：生成课程知识图谱

1. 启动Whisper服务
2. 启动Java后端
3. 登录系统 → 课程管理
4. 点击"生成知识图谱"
5. 系统自动：
   - 调用Whisper转录所有视频
   - 调用AI抽取知识点
   - 生成知识图谱

### 场景2：生成章节知识图谱

1. 启动Whisper服务
2. 启动Java后端
3. 登录系统 → 章节管理
4. 选择章节 → "生成知识图谱"
5. 系统自动处理该章节的视频

---

## ✅ 检查清单

**启动前**：
- [ ] Python 3.8+ 已安装
- [ ] ffmpeg 已安装并添加到PATH
- [ ] 网络连接正常（首次需要下载模型）

**安装依赖**：
- [ ] 运行 `pip install openai-whisper flask flask-cors`
- [ ] 看到 "Successfully installed"

**启动服务**：
- [ ] 运行 `python whisper_server.py`
- [ ] 看到 "Running on http://0.0.0.0:5000"
- [ ] 窗口保持打开

**验证服务**：
- [ ] 访问 http://localhost:5000/health
- [ ] 返回 `{"status": "ok"}`

---

## 📊 性能参数

### Whisper模型对比

| 模型 | 大小 | 速度 | 准确率 | 当前使用 |
|------|------|------|--------|---------|
| tiny | 39MB | 最快 | 85% | ✅ 是 |
| base | 74MB | 快 | 95% | - |
| small | 244MB | 中等 | 97% | - |
| medium | 769MB | 慢 | 98% | - |
| large | 1550MB | 很慢 | 99% | - |

### 处理速度（tiny模型）

| 视频时长 | 处理时间 | 说明 |
|---------|---------|------|
| 1分钟 | ~3秒 | 实时的3倍速 |
| 5分钟 | ~15秒 | 实时的20倍速 |
| 10分钟 | ~30秒 | 实时的20倍速 |

---

## 🎉 总结

**Whisper服务的作用**：
- 将视频语音转换成文字
- 让AI能够从实际讲解内容中抽取知识点
- 大幅提升知识点数量和质量

**启动步骤**：
1. `pip install openai-whisper flask flask-cors`（首次）
2. `python whisper_server.py`（每次使用）
3. 保持窗口打开

**验证成功**：
- 看到 "Running on http://0.0.0.0:5000"
- 访问 http://localhost:5000/health 返回正常

---

**现在您可以开始使用了！** 🚀

